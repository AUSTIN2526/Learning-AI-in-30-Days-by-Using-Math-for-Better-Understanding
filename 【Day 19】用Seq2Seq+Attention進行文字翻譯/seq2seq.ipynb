{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from opencc import OpenCC\n",
    "\n",
    "def convert_news_to_csv(data_path, csv_file_path):\n",
    "    cc = OpenCC('s2tw') # 簡體轉繁體\n",
    "    with open(data_path, 'r', encoding = \"utf-8\") as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        english, chinese = [], []\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                en, cn, _, = line.split('\\t') # 資料是\\t分割的\n",
    "                english.append(en)\n",
    "                \n",
    "                chinese.append(cc.convert(cn))\n",
    "    df = pd.DataFrame({'chinese':chinese, 'english':english})\n",
    "    df.to_csv(csv_file_path)\n",
    "    \n",
    "convert_news_to_csv('cmn.txt', 'translate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class TranslateDataset(Dataset):\n",
    "    def __init__(self, x, y, src_tokenizer, tgt_tokenizer):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def collate_fn(self, batch):    \n",
    "        batch_x, batch_y = zip(*batch)\n",
    "        inputs = self.src_tokenizer(batch_x, max_length=256, truncation=True, padding=\"longest\", return_tensors='pt').input_ids[:, 1:]\n",
    "        targets = self.tgt_tokenizer(batch_y, max_length=256, truncation=True, padding=\"longest\", return_tensors='pt').input_ids\n",
    "       \n",
    "        return {'src_input_ids':inputs, 'tgt_input_ids': targets}\n",
    "\n",
    "df = pd.read_csv('translate.csv')\n",
    "input_texts = df['chinese'].values\n",
    "target_texts = df['english'].values\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_texts, target_texts, train_size=0.8, random_state=46, shuffle=True)\n",
    "\n",
    "src_tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n",
    "tgt_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "trainset = TranslateDataset(x_train, y_train, src_tokenizer, tgt_tokenizer)\n",
    "validset = TranslateDataset(x_valid, y_valid, src_tokenizer, tgt_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size = 64, shuffle = True, num_workers = 0, pin_memory = True, collate_fn=trainset.collate_fn)\n",
    "valid_loader = DataLoader(validset, batch_size = 64, shuffle = True, num_workers = 0, pin_memory = True, collate_fn=validset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, padding_idx):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        embedded = self.dropout(self.embedding(token_ids))\n",
    "        #embedded: (batch_size, time_step, emb_dim)\n",
    "        output, hidden = self.gru(embedded) \n",
    "        # output: (batch_size, time_step, hidden_size * 2)\n",
    "        # hidden: (2, batch_size, hidden_size)\n",
    "        return output, hidden\n",
    "    \n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.encoder_projection = nn.Linear(hidden_size, hidden_size)\n",
    "        self.decoder_projection = nn.Linear(hidden_size, hidden_size)\n",
    "        self.attention_v = nn.Linear(hidden_size, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, encoder_hidden, decoder_hidden):\n",
    "        energy = self.tanh(self.encoder_projection(encoder_hidden) + self.decoder_projection(decoder_hidden))\n",
    "        #energy: (batch_size, time_step, hidden_size)\n",
    "        scores = self.attention_v(energy)\n",
    "        #scores: (batch_size, time_step, 1)\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        #scores: (batch_size, 1, time_step)\n",
    "\n",
    "        attention_weights = self.softmax(scores)\n",
    "        # attention_weights (batch_size, 1, time_step)\n",
    "        context_vector = torch.bmm(attention_weights, decoder_hidden)\n",
    "        #context_vector: (batch_size, 1, hidden_size)\n",
    "        return context_vector\n",
    "    \n",
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, attention, hidden_size, output_size, padding_idx):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.output_projection = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.attention = attention\n",
    "\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_hidden, decoder_input_ids):\n",
    "        # decoder_input_ids: (batch_size, 1)\n",
    "        embedded = self.dropout(self.embedding(decoder_input_ids)) \n",
    "        # embedded: (1, batch_size, emb_dim)\n",
    "        decoder_state = decoder_hidden.permute(1, 0, 2) \n",
    "        #decoder_state (batch_size, 1, emb_dim)\n",
    "        context = self.attention(decoder_state, encoder_outputs) \n",
    "        # (batch_size, 1, hidden_size)\n",
    "        input_gru = torch.cat((embedded, context), dim=-1) \n",
    "        # input_gru (batch_size, 1, hidden_size + emb_dim)\n",
    "        output, decoder_hidden = self.gru(input_gru, decoder_hidden) \n",
    "        # output: (batch_size, time_step, hidden_size)\n",
    "        # decoder_hidden: (1, batch_size, hidden_size)\n",
    "        decoder_output = self.output_projection(output)\n",
    "        # decoder_output: (batch_size, 1, output_size)\n",
    "        return decoder_output, decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attentionseq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, padding_idx):\n",
    "        super(Attentionseq2seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.criterion = nn.NLLLoss(ignore_index=padding_idx)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, src_input_ids, tgt_input_ids):\n",
    "        input_ids = src_input_ids\n",
    "        targets = tgt_input_ids\n",
    "\n",
    "        # Encoder\n",
    "        encoder_outputs, decoder_hidden = self.encoder(input_ids)\n",
    "        # encoder_outputs: (batch_size, time_step, hidden_size)\n",
    "        # decoder_hidden: (1, batch_size, hidden_size)\n",
    "        decoder_next_input = torch.empty(targets.shape[0], 1, dtype=torch.long).fill_(101).to(input_ids.device.type) # 加入CLS token\n",
    "        # decoder_next_input: (batch_size, 1)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_outputs = []\n",
    "        for i in range(targets.shape[1]):\n",
    "            decoder_next_input, decoder_hidden = self.decoder(encoder_outputs, decoder_hidden, decoder_next_input)\n",
    "            # decoder_next_input: (batch_size, 1, hidden_size)\n",
    "            # decoder_hidden: (1, batch_size, hidden_size)\n",
    "\n",
    "            decoder_outputs.append(decoder_next_input)      # 儲存當前時序的文字分布狀態\n",
    "            decoder_next_input = targets[:, i].unsqueeze(1) # 取出下一個對應的文字進行生成\n",
    "            # decoder_next_input: (batch_size, 1)\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) # 完整的Decoder隱狀態輸出\n",
    "        # decoder_outputs: (batch_size, time_step, output_dim)\n",
    "        decoder_outputs = self.logsoftmax(decoder_outputs)  # 計算個文字機率\n",
    "        # decoder_outputs: (batch_size, time_step, output_dim)\n",
    "       \n",
    "        # 計算損失值\n",
    "        loss = self.criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), # (batch_size * time_step,  output_dim)\n",
    "            targets.view(-1) # (batch_size * time_step)\n",
    "        )\n",
    "        \n",
    "        return loss, decoder_outputs\n",
    "    \n",
    "    def generate(self, input_ids, sos_token=101, eos_token=102, max_len=50):\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, decoder_hidden = self.encoder(input_ids)\n",
    "            decoder_outputs = []\n",
    "            decoder_next_input = torch.empty(1, 1, dtype=torch.long).fill_(sos_token).to(input_ids.device.type)\n",
    "            for _ in range(max_len):\n",
    "                decoder_next_input, decoder_hidden = self.decoder(encoder_outputs, decoder_hidden, decoder_next_input)\n",
    "                decoder_outputs.append(decoder_next_input)\n",
    "\n",
    "                _, top_token_index = decoder_next_input.topk(1)\n",
    "                if top_token_index == eos_token:\n",
    "                    break\n",
    "                \n",
    "                decoder_next_input = top_token_index.squeeze(-1).detach()  # detach from history as input\n",
    "            decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "            decoder_outputs = self.logsoftmax(decoder_outputs)\n",
    "\n",
    "            _, generated_ids = decoder_outputs.topk(1)\n",
    "        return generated_ids.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from Trainer import Trainer\n",
    "\n",
    "# 主程式部分\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_size = 768\n",
    "encoder = EncoderGRU(\n",
    "    vocab_size=len(src_tokenizer), \n",
    "    hidden_size=hidden_size, \n",
    "    padding_idx=src_tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "decoder = DecoderGRU(\n",
    "    attention = BahdanauAttention(hidden_size=hidden_size),\n",
    "    hidden_size=hidden_size, \n",
    "    output_size=len(tgt_tokenizer), \n",
    "    padding_idx=tgt_tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "model = Attentionseq2seq(\n",
    "    encoder = encoder,\n",
    "    decoder = decoder,\n",
    "    padding_idx = tgt_tokenizer.pad_token_id\n",
    ").to(device)\n",
    "\n",
    "optimizer_e = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "optimizer_d = optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "trainer = Trainer(\n",
    "    epochs=30, \n",
    "    train_loader=train_loader, \n",
    "    valid_loader=valid_loader, \n",
    "    model=model, \n",
    "    optimizer=[optimizer_e, optimizer_d],\n",
    "    early_stopping=3\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "model.eval()\n",
    "\n",
    "for idx in range(3):\n",
    "    input_ids = src_tokenizer(x_valid[idx], max_length=256, truncation=True, padding=\"longest\", return_tensors='pt').to(device).input_ids[:, 1:]\n",
    "    generated_ids = model.generate(input_ids, max_len=20)\n",
    "    print('\\n輸入文字:', x_valid[idx])\n",
    "    print('目標文字:', y_valid[idx])\n",
    "    print('翻譯文字:', tgt_tokenizer.decode(generated_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
